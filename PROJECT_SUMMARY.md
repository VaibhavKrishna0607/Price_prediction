# ğŸ“± Mobile Price Predictor - Project Summary

## ğŸ¯ Project Overview

This is a complete **Smartphone Price Predictor** web application that predicts smartphone price ranges using machine learning. It includes a modern frontend, a Flask backend, and optional AWS SageMaker integration for cloud training and deployment.

## âœ… What's Included

### Frontend (Modern UI)
- âœ¨ **HTML5** - Responsive, semantic markup
- ğŸ¨ **CSS3** - Modern design with gradients, animations, and responsive layout
- âš¡ **JavaScript** - Form validation, API calls, and dynamic UI updates
- ğŸ“± **Mobile-friendly** - Works on all devices

### Backend (Flask)
- ğŸ”§ **Flask Application** (`app.py`) - Main application server
- ğŸ”Œ **RESTful API** - `/predict`, `/health`, `/endpoint-status` endpoints
- ğŸ›¡ï¸ **Error Handling** - Graceful error handling and fallbacks
- ğŸ§ª **Mock Mode** - Works without AWS for testing

### AWS Integration
- â˜ï¸ **AWS SageMaker** - Model training and deployment
- ğŸ“¦ **S3 Integration** - Data and model storage
- ğŸ” **IAM Support** - Secure credential management
- ğŸ”„ **Automatic Fallback** - Falls back to mock predictions if AWS unavailable

### Machine Learning
- ğŸ¤– **Random Forest Classifier** - ML model for price prediction
- ğŸ“Š **Training Scripts** - Local and SageMaker training support
- ğŸ¯ **20 Features** - Comprehensive smartphone specifications

### Documentation
- ğŸ“– **README.md** - Complete project documentation
- ğŸš€ **QUICKSTART.md** - Quick start guide
- ğŸ”§ **AWS_SETUP_GUIDE.md** - Detailed AWS setup instructions
- ğŸ“ **This file** - Project summary

## ğŸ“‚ Project Structure

```
mobile-price-predictor/
â”‚
â”œâ”€â”€ app.py                    # Flask application (main server)
â”œâ”€â”€ aws_integration.py        # AWS SageMaker integration module
â”œâ”€â”€ train_model.py            # Local training script
â”œâ”€â”€ sagemaker_train.py        # SageMaker training script
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ .gitignore               # Git ignore rules
â”œâ”€â”€ env_example.txt          # Environment variables template
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html           # Frontend HTML template
â”‚
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ styles.css           # CSS styles
â”‚   â””â”€â”€ app.js               # JavaScript for frontend
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ README.md            # Main documentation
    â”œâ”€â”€ QUICKSTART.md        # Quick start guide
    â”œâ”€â”€ AWS_SETUP_GUIDE.md   # AWS setup guide
    â””â”€â”€ PROJECT_SUMMARY.md   # This file
```

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Run Application (Mock Mode - No AWS needed)
```bash
python app.py
```

### 3. Open Browser
Visit `http://localhost:5000`

### 4. Test Prediction
Fill in the form and click "Predict Price Range"

## ğŸ”‘ Key Features

### 1. **Mock Mode** (Testing without AWS)
- Works immediately without AWS setup
- Rule-based predictions for testing
- Perfect for development and demos

### 2. **AWS SageMaker Integration** (Production)
- Real ML model predictions
- Scalable cloud deployment
- Automatic fallback to mock if AWS unavailable

### 3. **Modern UI**
- Beautiful gradient design
- Responsive layout
- Smooth animations
- Form validation

### 4. **API Endpoints**
- `POST /predict` - Get price prediction
- `GET /health` - Health check
- `GET /endpoint-status` - Check AWS endpoint status

## ğŸ¨ Price Categories

The model predicts 4 price ranges:

1. **ğŸ’° Budget** (0) - â‚¹0 - â‚¹10,000
2. **ğŸ“± Lower Mid-range** (1) - â‚¹10,000 - â‚¹20,000
3. **ğŸ¯ Upper Mid-range** (2) - â‚¹20,000 - â‚¹35,000
4. **ğŸ’ Premium** (3) - â‚¹35,000+

## ğŸ“Š Input Features (20 Features)

1. Battery Power (mAh)
2. Bluetooth
3. Clock Speed (GHz)
4. Dual SIM
5. Front Camera (MP)
6. 4G Support
7. Internal Memory (GB)
8. Mobile Depth (cm)
9. Mobile Weight (grams)
10. Number of Cores
11. Primary Camera (MP)
12. Pixel Height
13. Pixel Width
14. RAM (MB)
15. Screen Height (cm)
16. Screen Width (cm)
17. Talk Time (hours)
18. 3G Support
19. Touch Screen
20. WiFi

## ğŸ”§ Configuration

### Environment Variables

Create a `.env` file from `env_example.txt`:

```env
# AWS Configuration (optional for mock mode)
AWS_ACCESS_KEY_ID=your-key
AWS_SECRET_ACCESS_KEY=your-secret
AWS_REGION=us-east-1
SAGEMAKER_ENDPOINT=mobile-price-predictor-endpoint
SAGEMAKER_ROLE=arn:aws:iam::account:role/SageMakerRole

# Flask Configuration
FLASK_ENV=development
SECRET_KEY=your-secret-key
PORT=5000

# S3 Configuration
S3_BUCKET_NAME=your-bucket-name
```

## ğŸ“š Documentation Files

1. **README.md** - Complete project documentation
2. **QUICKSTART.md** - Quick start guide (5 minutes)
3. **AWS_SETUP_GUIDE.md** - Step-by-step AWS setup
4. **PROJECT_SUMMARY.md** - This file

## ğŸ§ª Testing

### Test Without AWS (Mock Mode)
```bash
python app.py
# App automatically uses mock predictions
```


## FAQs (What/Why/Alternatives)

### Problem framing
- **Task type**: Multiclass classification of price range (labels 0â€“3). Not regression because the dataset provides discrete price buckets, not continuous prices.
- **Metric we watch**: Overall accuracy and classwise precision/recall/F1; confusion matrix to see which ranges confuse the model.

### Model choice
- **Chosen model**: `RandomForestClassifier`.
  - **Why**: Handles nonlinear interactions, robust to outliers, minimal feature scaling, works well on tabular numeric + binary features, fast to train, good baseline with interpretability (feature importances).
  - **Tuning**: Optional `RandomizedSearchCV` with 5â€‘fold CV; class_weight='balanced_subsample' to reduce class imbalance bias.
  - **Result**: ~0.91 test accuracy after feature engineering.
- **Alternatives and tradeâ€‘offs**:
  - **XGBoost/LightGBM/CatBoost**: Often stronger on tabular data; more knobs, sometimes higher accuracy with longer tuning. We can swap later for more performance.
  - **Logistic Regression/Linear SVM**: Fast and simple; may underfit due to nonlinear relationships. Requires careful scaling/regularization.
  - **Neural nets**: Usually overkill for small tabular datasets; more sensitive to preprocessing.
  - **kNN**: Simple but slow at inference, sensitive to scaling, and memory heavy.

### Features used (raw + engineered)
- **Base (20) features from the dataset**: `battery_power, blue, clock_speed, dual_sim, fc, four_g, int_memory, m_dep, mobile_wt, n_cores, pc, px_height, px_width, ram, sc_h, sc_w, talk_time, three_g, touch_screen, wifi`.
- **Engineered features (why they help)**:
  - `pixel_area = px_height * px_width`: proxy for total display resolution.
  - `ppi â‰ˆ diag(px)/sc_h`: pixel density approximation, correlates with screen quality.
  - `screen_ratio = sc_h/sc_w`: shape aspect (content/UX proxy).
  - `ram_per_core = ram/n_cores`: balanced compute/memory capacity proxy.
  - `battery_per_weight = battery_power/mobile_wt`: usability/efficiency proxy.
- These capture interactions nonlinearly and gave a measurable lift in accuracy.

### Data handling
- **Train/validation split**: Stratified 80/20 to preserve class balance.
- **No scaling/encoding required**: All inputs are numeric or binary; trees are scaleâ€‘invariant.
- **Target**: `price_range` discovered/validated in preprocessing with fallbacks for alternate names.

### Artifacts
- We save a bundle `{ model, feature_columns }` in `model.pkl` so inference code always knows the exact feature order.

### AWS components (roles and significance)
- **Amazon S3**: Durable object storage for dataset (`training/train.csv`), source code bundle (`code/code.zip`), and training outputs (`output/model.tar.gz`). Decouples data/code from compute and is accessible to both your laptop and SageMaker.
- **AWS IAM**: Secure permissions. The execution role needs S3 read/write and ECR read permissions to pull the framework container.
- **Amazon SageMaker â€“ Training**: Managed compute to run `sagemaker_train.py` in the scikitâ€‘learn container. Benefits: reproducible environments, logs/metrics, larger instances on demand, output model persisted to S3.
- **Amazon SageMaker â€“ Inference (optional)**: Host the trained artifact as a HTTPS endpoint for your website/app. SageMaker handles autoscaling, health checks, and monitoring.

### Why SageMaker vs local
- **Local**: Fast iteration, zero cloud cost, great for development. We used it to prove accuracy and export a model.
- **SageMaker**: Needed when data/compute/availability requirements exceed a laptop, or when you want a managed API endpoint with monitoring and scaling.

### Deployment options
- **Simple (local)**: Flask app loads `model.pkl`, exposes `/predict`, serves HTML form.
- **Managed (cloud)**: Deploy on SageMaker endpoint; front end calls the endpoint via `boto3` or API Gateway. Alternative: Lambda + Docker for lowâ€‘cost bursty traffic.

### Cost/operational notes
- Training jobs are payâ€‘perâ€‘use; endpoints are billed while runningâ€”shut down when not needed. Use `t3`/`m5` families without GPUs for this tabular model.

### Common pitfalls and how we addressed them
- Wrong feature order at inference â†’ store and reuse `feature_columns` with the model.
- Missing permissions pulling the container â†’ add `AmazonEC2ContainerRegistryReadOnly` to the execution role.
- S3 path mistakes (folder vs object) â†’ always end training prefixes with `/` and name files explicitly (`train.csv`).

### How to justify choices succinctly (interviewâ€‘style)
- We framed the task as multiclass classification because labels are discrete. Chose Random Forest for strong tabular baselines with minimal preprocessing and added targeted feature engineering that captures resolution, density, aspect ratio, compute/memory balance, and battery efficiencyâ€”these correlate with price tiers. We validated with stratified splits and improved accuracy to ~0.91. We use S3 for durable data/model storage and SageMaker to run the same script in a managed container with reproducible environments and optional production deployment as an endpoint.

